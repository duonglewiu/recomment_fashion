import numpy as np
import pickle as pkl
import tensorflow as tf
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.preprocessing import image
from tensorflow.keras.layers import GlobalMaxPool2D

from sklearn.neighbors import NearestNeighbors
import os
from numpy.linalg import norm
import streamlit as st
from PIL import Image
import cv2  # Th√™m th∆∞ vi·ªán OpenCV

st.set_page_config(layout="wide")
st.header('üëï Fashion Recommendation System üëö')


# === Load data ===
@st.cache_resource
def load_data():
    try:
        Image_features = pkl.load(open('Images_features.pkl', 'rb'))
        filenames = pkl.load(open('filenames.pkl', 'rb'))

        # --- ƒê√É S·ª¨A (QUAN TR·ªåNG) ---
        # Thay th·∫ø ƒë∆∞·ªùng d·∫´n "cloud" (t·ª´ file pkl) b·∫±ng ƒë∆∞·ªùng d·∫´n "local"
        # Gi·∫£ s·ª≠ th∆∞ m·ª•c ·∫£nh local c·ªßa b·∫°n t√™n l√† 'images'

        # X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n g·ªëc tr√™n cloud (d·ª±a tr√™n l·ªói)
        cloud_base_path = "/kaggle/input/fashion-product-images-small/images/"
        local_base_path = "images/"  # Th∆∞ m·ª•c local ch·ª©a ·∫£nh

        filenames = [f.replace(cloud_base_path, local_base_path) for f in filenames]

        st.success(f"ƒê√£ t·∫£i {len(filenames)} ƒë∆∞·ªùng d·∫´n ·∫£nh v√† s·ª≠a v·ªÅ local. (V√≠ d·ª•: {filenames[0]})")

        return Image_features, filenames
    except FileNotFoundError as e:
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y file {e.filename}.")
        st.error("H√£y ch·∫Øc ch·∫Øn r·∫±ng b·∫°n c√≥ 'Images_features.pkl' v√† 'filenames.pkl' trong c√πng th∆∞ m·ª•c.")
        return None, None
    except Exception as e:
        st.error(f"ƒê√£ x·∫£y ra l·ªói khi t·∫£i d·ªØ li·ªáu: {e}")
        return None, None


Image_features, filenames = load_data()


# === Model setup ===
@st.cache_resource
def get_model():
    # ... (Ph·∫ßn c√≤n l·∫°i c·ªßa file gi·ªØ nguy√™n) ...
    model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    model.trainable = False
    model_sequential = tf.keras.models.Sequential([model, GlobalMaxPool2D()])
    return model_sequential


# H√†m tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng
def extract_features_from_images(image_path, model):
    img = image.load_img(image_path, target_size=(224, 224))
    img_array = image.img_to_array(img)
    img_expand_dim = np.expand_dims(img_array, axis=0)
    img_preprocess = preprocess_input(img_expand_dim)
    result = model.predict(img_preprocess).flatten()
    norm_result = result / norm(result)
    return norm_result


# === Model Super-Resolution (L√ÄM N√âT) ===
@st.cache_resource
def get_super_res_model():
    """T·∫£i model AI l√†m n√©t ·∫£nh (ch·ªâ t·∫£i 1 l·∫ßn)"""
    model_path = "FSRCNN_x4.pb"  # ƒê√É S·ª¨A: t·ª´ g·∫°ch ngang (-) th√†nh g·∫°ch d∆∞·ªõi (_)
    if not os.path.exists(model_path):
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y model Super-Resolution '{model_path}'.")
        st.info("Vui l√≤ng t·∫£i file 'FSRCNN-x4.pb' v·ªÅ c√πng th∆∞ m·ª•c v·ªõi app.")
        return None

    try:
        sr = cv2.dnn_superres.DnnSuperResImpl_create()
        sr.readModel(model_path)
        sr.setModel("fsrcnn", 4)  # T√™n thu·∫≠t to√°n "fsrcnn", ph√≥ng to 4 l·∫ßn (x4)
        return sr
    except cv2.error as e:
        st.error(f"L·ªói khi t·∫£i model OpenCV. H√£y ch·∫Øc ch·∫Øn b·∫°n ƒë√£ c√†i 'opencv-python-contrib'. L·ªói: {e}")
        return None


# Ch·ªâ ch·∫°y n·∫øu ƒë√£ load data th√†nh c√¥ng
if Image_features is not None and filenames is not None:
    model = get_model()
    sr_model = get_super_res_model()  # T·∫£i model l√†m n√©t


    # === Neighbors setup ===
    @st.cache_resource
    def get_neighbors():
        neighbors = NearestNeighbors(n_neighbors=6, algorithm='brute', metric='euclidean')
        neighbors.fit(Image_features)
        return neighbors


    neighbors = get_neighbors()

    # === Upload ·∫£nh ===
    os.makedirs('upload', exist_ok=True)
    upload_file = st.file_uploader("Upload an image to find similar fashion items")

    if upload_file is not None:
        upload_path = os.path.join('upload', upload_file.name)
        with open(upload_path, 'wb') as f:
            f.write(upload_file.getbuffer())

        # Chia layout: 1 c·ªôt cho ·∫£nh upload, 1 c·ªôt cho ·∫£nh n√©t
        col1, col2 = st.columns([1, 2])  # C·ªôt ·∫£nh n√©t r·ªông g·∫•p ƒë√¥i

        with col1:
            st.subheader('Uploaded Image')
            st.image(upload_path, caption="Your Upload", width=250)

        # Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng t·ª´ ·∫£nh upload
        input_img_features = extract_features_from_images(upload_path, model)
        distance, indices = neighbors.kneighbors([input_img_features])

        # ===============================
        # === Recommended Images ===
        # ===============================
        st.subheader("Recommended Images")

        # CSS ƒë·ªÉ bo g√≥c ·∫£nh
        st.markdown("""
        <style>
            .stImage > img {
                border-radius: 10px;
            }
            .stButton { 
                display: flex;
                justify-content: center;
            }
        </style>
        """, unsafe_allow_html=True)

        if "selected_image" not in st.session_state:
            st.session_state.selected_image = None

        cols = st.columns(5)
        recommended_image_paths = []
        for i, col in enumerate(cols, start=1):
            img_path = filenames[indices[0][i]]
            recommended_image_paths.append(img_path)

            if os.path.exists(img_path):
                col.image(img_path, caption=f"Similar {i}", use_column_width=True)
                if col.button(f"View Details {i}", key=f"view_{i}", use_container_width=True):
                    st.session_state.selected_image = img_path
            else:
                col.warning(f"‚ö†Ô∏è Missing: {img_path}")

        # Ghi ƒë√® ·∫£nh ƒë·∫ßu ti√™n n·∫øu kh√¥ng c√≥ g√¨ ƒë∆∞·ª£c ch·ªçn
        if st.session_state.selected_image is None and recommended_image_paths:
            st.session_state.selected_image = recommended_image_paths[0]

        # ===============================
        # === HI·ªÇN TH·ªä ·∫¢NH N√âT (ƒê√É S·ª¨A) ===
        # ===============================
        with col2:
            if st.session_state.selected_image:
                if os.path.exists(st.session_state.selected_image):
                    st.subheader("üîé AI Enhanced View (x4)")

                    # Ki·ªÉm tra xem model AI ƒë√£ t·∫£i ƒë∆∞·ª£c ch∆∞a
                    if sr_model is None:
                        st.warning("Kh√¥ng th·ªÉ l√†m n√©t ·∫£nh (model AI ch∆∞a s·∫µn s√†ng). Hi·ªÉn th·ªã ·∫£nh g·ªëc.")
                        st.image(st.session_state.selected_image,
                                 caption="Original Image (Low-Res)",
                                 use_column_width=True)
                    else:
                        try:
                            # T·∫£i ·∫£nh g·ªëc (b·∫±ng cv2)
                            img_goc = cv2.imread(st.session_state.selected_image)

                            if img_goc is None:
                                st.error(f"Kh√¥ng th·ªÉ ƒë·ªçc file ·∫£nh: {st.session_state.selected_image}")
                            else:
                                # (T√πy ch·ªçn) Hi·ªÉn th·ªã spinner
                                with st.spinner(f"ƒêang d√πng AI ƒë·ªÉ l√†m n√©t (ph√≥ng to x4)..."):
                                    result_net = sr_model.upsample(img_goc)

                                # Hi·ªÉn th·ªã ·∫£nh ƒë√£ l√†m n√©t
                                st.image(result_net,
                                         caption="AI Upscaled Image",
                                         use_column_width=True,
                                         channels="BGR")  # Quan tr·ªçng: cv2 ƒë·ªçc l√† BGR

                                # (T√πy ch·ªçn) Hi·ªÉn th·ªã k√≠ch th∆∞·ªõc th·∫≠t
                                st.caption(
                                    f"Original: {img_goc.shape[1]}x{img_goc.shape[0]} px | Enhanced: {result_net.shape[1]}x{result_net.shape[0]} px")

                        except Exception as e:
                            st.error(f"L·ªói khi ƒëang l√†m n√©t ·∫£nh: {e}")
                            st.image(st.session_state.selected_image,
                                     caption="Fallback to Original Image",
                                     use_column_width=True)  # Hi·ªÉn th·ªã ·∫£nh g·ªëc n·∫øu c√≥ l·ªói
                else:
                    st.error(f"Kh√¥ng th·ªÉ t√¨m th·∫•y file ·∫£nh: {st.session_state.selected_image}")

else:
    st.info("Vui l√≤ng t·∫£i file 'Images_features.pkl' v√† 'filenames.pkl' ƒë·ªÉ b·∫Øt ƒë·∫ßu.")



